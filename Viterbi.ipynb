{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W_C4ucq8bNYU"
      },
      "outputs": [],
      "source": [
        "from pydoc import text\n",
        "import sys, time\n",
        "from nltk import tokenize\n",
        "from nltk.grammar import PCFG\n",
        "from nltk.parse import pchart\n",
        "from nltk.parse import ViterbiParser\n",
        "from functools import reduce\n",
        "from tabulate import tabulate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwuyI91IbLDx",
        "outputId": "905cc5d7-775d-4342-f536-70b1f5002690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "s: student saw tiger with binocular\n",
            "parser: <ViterbiParser for <Grammar with 12 productions>>\n",
            "grammar: Grammar with 12 productions (start state = S)\n",
            "    S -> NP VP [1.0]\n",
            "    PP -> P NP [1.0]\n",
            "    VP -> V NP [0.7]\n",
            "    VP -> VP PP [0.3]\n",
            "    P -> 'with' [1.0]\n",
            "    V -> 'saw' [1.0]\n",
            "    NP -> NP PP [0.4]\n",
            "    NP -> 'student' [0.1]\n",
            "    NP -> 'binocular' [0.18]\n",
            "    NP -> 'saw' [0.04]\n",
            "    NP -> 'tiger' [0.18]\n",
            "    NP -> 'telescopes' [0.1]\n",
            "\n",
            "Inserting tokens into the most likely constituents table...\n",
            "   Insert: |=....| student\n",
            "   Insert: |.=...| saw\n",
            "   Insert: |..=..| tiger\n",
            "   Insert: |...=.| with\n",
            "   Insert: |....=| binocular\n",
            "Finding the most likely constituents spanning 1 text elements...\n",
            "   Insert: |=....| NP -> 'student' [0.1]            0.1000000000 \n",
            "   Insert: |.=...| V -> 'saw' [1.0]                 1.0000000000 \n",
            "   Insert: |.=...| NP -> 'saw' [0.04]               0.0400000000 \n",
            "   Insert: |..=..| NP -> 'tiger' [0.18]             0.1800000000 \n",
            "   Insert: |...=.| P -> 'with' [1.0]                1.0000000000 \n",
            "   Insert: |....=| NP -> 'binocular' [0.18]         0.1800000000 \n",
            "Finding the most likely constituents spanning 2 text elements...\n",
            "   Insert: |.==..| VP -> V NP [0.7]                 0.1260000000 \n",
            "   Insert: |...==| PP -> P NP [1.0]                 0.1800000000 \n",
            "Finding the most likely constituents spanning 3 text elements...\n",
            "   Insert: |===..| S -> NP VP [1.0]                 0.0126000000 \n",
            "   Insert: |..===| NP -> NP PP [0.4]                0.0129600000 \n",
            "Finding the most likely constituents spanning 4 text elements...\n",
            "   Insert: |.====| VP -> V NP [0.7]                 0.0090720000 \n",
            "  Discard: |.====| VP -> VP PP [0.3]                0.0068040000 \n",
            "  Discard: |.====| VP -> VP PP [0.3]                0.0068040000 \n",
            "Finding the most likely constituents spanning 5 text elements...\n",
            "   Insert: |=====| S -> NP VP [1.0]                 0.0009072000 \n",
            "\n",
            "╒═══════════════╤════════╤══════════════╤═════════════╤════════════════════╕\n",
            "│ Parser        │   Beam │   Time(secs) │     #Parses │   Average P(parse) │\n",
            "╞═══════════════╪════════╪══════════════╪═════════════╪════════════════════╡\n",
            "│ ViterbiParser │      0 │            0 │           1 │          0.0009072 │\n",
            "╘═══════════════╧════════╧══════════════╧═════════════╧════════════════════╛\n",
            "\n",
            "(S\n",
            "  (NP student)\n",
            "  (VP (V saw) (NP (NP tiger) (PP (P with) (NP binocular))))) [0.0009071999999999999]\n"
          ]
        }
      ],
      "source": [
        "toy_pcfg1 = PCFG.fromstring(\"\"\"\n",
        "S ->NP VP [1.0]\n",
        "PP ->P NP [1.0]\n",
        "VP ->V NP [0.7]\n",
        "VP ->VP PP [0.3]\n",
        "P -> 'with' [1.0]\n",
        "V -> 'saw' [1.0]\n",
        "NP ->NP PP [0.4]\n",
        "NP -> 'student' [0.1]\n",
        "NP -> 'binocular' [0.18]\n",
        "NP -> 'saw' [0.04]\n",
        "NP -> 'tiger' [0.18]\n",
        "NP -> 'telescopes' [0.1]\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "sent=\"student saw tiger with binocular\"\n",
        "grammar=toy_pcfg1\n",
        "tokens = sent.split()\n",
        "\n",
        "parsers = [ViterbiParser(grammar)]\n",
        "\n",
        "times = []\n",
        "average_p = []\n",
        "num_parses = []\n",
        "all_parses = {}\n",
        "for parser in parsers:\n",
        "    print('s: %s\\nparser: %s\\ngrammar: %s' % (sent,parser,grammar))\n",
        "    print()\n",
        "    parser.trace(3)\n",
        "    t = time.time()\n",
        "    parses = parser.parse_all(tokens)\n",
        "    times.append(time.time()-t)\n",
        "    if parses:\n",
        "        p = reduce(lambda a,b:a+b.prob(), parses, 0.0)\n",
        "    else:\n",
        "        p = 0\n",
        "    average_p.append(p)\n",
        "    num_parses.append(len(parses))\n",
        "    for p in parses:\n",
        "        all_parses[p.freeze()] = 1\n",
        "\n",
        "stat=[]\n",
        "print()\n",
        "for i in range(len(parsers)):\n",
        "    temp=[]\n",
        "    temp.append('%19s'%parsers[i].__class__.__name__),\n",
        "    temp.append('%4d'%getattr(parsers[0], \"beam_size\", 0))\n",
        "    temp.append('%11.4f'%times[i])\n",
        "    temp.append('%11d'%num_parses[i])\n",
        "    temp.append('%19.14f'%average_p[i])\n",
        "    stat.append(temp)\n",
        "print(tabulate(stat,headers=[\"Parser\",\"Beam\",\"Time(secs)\",\"#Parses\",\"Average P(parse)\"],tablefmt=\"fancy_grid\"))\n",
        "parses = all_parses.keys()\n",
        "if parses:\n",
        "    p = reduce(lambda a,b:a+b.prob(), parses, 0)/len(parses)\n",
        "else:\n",
        "    p = 0\n",
        "print()\n",
        "\n",
        "for parse in parses:\n",
        "    print(parse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnSXxjV1bQzo",
        "outputId": "4f754d39-21b1-4493-8820-680518992a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "s: student saw tiger with binocular\n",
            "parser: <ViterbiParser for <Grammar with 12 productions>>\n",
            "grammar: Grammar with 12 productions (start state = S)\n",
            "    S -> NP NP [1.0]\n",
            "    PP -> P NP [1.0]\n",
            "    VP -> V NP [0.7]\n",
            "    VP -> VP PP [0.3]\n",
            "    P -> 'with' [1.0]\n",
            "    V -> 'saw' [1.0]\n",
            "    NP -> NP PP [0.4]\n",
            "    NP -> 'student' [0.1]\n",
            "    NP -> 'binocular' [0.18]\n",
            "    NP -> 'saw' [0.04]\n",
            "    NP -> 'tiger' [0.18]\n",
            "    NP -> 'telescopes' [0.1]\n",
            "\n",
            "Inserting tokens into the most likely constituents table...\n",
            "   Insert: |=....| student\n",
            "   Insert: |.=...| saw\n",
            "   Insert: |..=..| tiger\n",
            "   Insert: |...=.| with\n",
            "   Insert: |....=| binocular\n",
            "Finding the most likely constituents spanning 1 text elements...\n",
            "   Insert: |=....| NP -> 'student' [0.1]            0.1000000000 \n",
            "   Insert: |.=...| V -> 'saw' [1.0]                 1.0000000000 \n",
            "   Insert: |.=...| NP -> 'saw' [0.04]               0.0400000000 \n",
            "   Insert: |..=..| NP -> 'tiger' [0.18]             0.1800000000 \n",
            "   Insert: |...=.| P -> 'with' [1.0]                1.0000000000 \n",
            "   Insert: |....=| NP -> 'binocular' [0.18]         0.1800000000 \n",
            "Finding the most likely constituents spanning 2 text elements...\n",
            "   Insert: |==...| S -> NP NP [1.0]                 0.0040000000 \n",
            "   Insert: |.==..| S -> NP NP [1.0]                 0.0072000000 \n",
            "   Insert: |.==..| VP -> V NP [0.7]                 0.1260000000 \n",
            "   Insert: |...==| PP -> P NP [1.0]                 0.1800000000 \n",
            "Finding the most likely constituents spanning 3 text elements...\n",
            "   Insert: |..===| NP -> NP PP [0.4]                0.0129600000 \n",
            "Finding the most likely constituents spanning 4 text elements...\n",
            "   Insert: |.====| S -> NP NP [1.0]                 0.0005184000 \n",
            "   Insert: |.====| VP -> V NP [0.7]                 0.0090720000 \n",
            "  Discard: |.====| VP -> VP PP [0.3]                0.0068040000 \n",
            "  Discard: |.====| VP -> VP PP [0.3]                0.0068040000 \n",
            "Finding the most likely constituents spanning 5 text elements...\n",
            "\n",
            "╒═══════════════╤════════╤══════════════╤═════════════╤════════════════════╕\n",
            "│ Parser        │   Beam │   Time(secs) │     #Parses │   Average P(parse) │\n",
            "╞═══════════════╪════════╪══════════════╪═════════════╪════════════════════╡\n",
            "│ ViterbiParser │      0 │        0.001 │           0 │                  0 │\n",
            "╘═══════════════╧════════╧══════════════╧═════════════╧════════════════════╛\n",
            "\n"
          ]
        }
      ],
      "source": [
        "toy_pcfg1 = PCFG.fromstring(\"\"\"\n",
        "S ->NP NP [1.0]\n",
        "PP ->P NP [1.0]\n",
        "VP ->V NP [0.7]\n",
        "VP ->VP PP [0.3]\n",
        "P -> 'with' [1.0]\n",
        "V -> 'saw' [1.0]\n",
        "NP ->NP PP [0.4]\n",
        "NP -> 'student' [0.1]\n",
        "NP -> 'binocular' [0.18]\n",
        "NP -> 'saw' [0.04]\n",
        "NP -> 'tiger' [0.18]\n",
        "NP -> 'telescopes' [0.1]\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "sent=\"student saw tiger with binocular\"\n",
        "grammar=toy_pcfg1\n",
        "tokens = sent.split()\n",
        "\n",
        "parsers = [ViterbiParser(grammar)]\n",
        "\n",
        "times = []\n",
        "average_p = []\n",
        "num_parses = []\n",
        "all_parses = {}\n",
        "for parser in parsers:\n",
        "    print('s: %s\\nparser: %s\\ngrammar: %s' % (sent,parser,grammar))\n",
        "    print()\n",
        "    parser.trace(3)\n",
        "    t = time.time()\n",
        "    parses = parser.parse_all(tokens)\n",
        "    times.append(time.time()-t)\n",
        "    if parses:\n",
        "        p = reduce(lambda a,b:a+b.prob(), parses, 0.0)\n",
        "    else:\n",
        "        p = 0\n",
        "    average_p.append(p)\n",
        "    num_parses.append(len(parses))\n",
        "    for p in parses:\n",
        "        all_parses[p.freeze()] = 1\n",
        "\n",
        "stat=[]\n",
        "print()\n",
        "for i in range(len(parsers)):\n",
        "    temp=[]\n",
        "    temp.append('%19s'%parsers[i].__class__.__name__),\n",
        "    temp.append('%4d'%getattr(parsers[0], \"beam_size\", 0))\n",
        "    temp.append('%11.4f'%times[i])\n",
        "    temp.append('%11d'%num_parses[i])\n",
        "    temp.append('%19.14f'%average_p[i])\n",
        "    stat.append(temp)\n",
        "print(tabulate(stat,headers=[\"Parser\",\"Beam\",\"Time(secs)\",\"#Parses\",\"Average P(parse)\"],tablefmt=\"fancy_grid\"))\n",
        "parses = all_parses.keys()\n",
        "if parses:\n",
        "    p = reduce(lambda a,b:a+b.prob(), parses, 0)/len(parses)\n",
        "else:\n",
        "    p = 0\n",
        "print()\n",
        "\n",
        "for parse in parses:\n",
        "    print(parse)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
